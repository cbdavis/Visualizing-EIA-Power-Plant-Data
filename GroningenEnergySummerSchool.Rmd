---
title: "Data Analysis and Visualization Tutorial"
author: "Chris Davis"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The shortened URL for this page is **[http://is.gd/GESS2016](http://is.gd/GESS2016)**

The journal article **[The State of the States: Data-driven Analysis of the US Clean Power Plan](http://www.sciencedirect.com/science/article/pii/S1364032116001271)** shows applications of the analysis and visualization shown here

### Introduction

There are a variety of different tools available which are useful for data visualization and analysis.  For dealing with large amounts of data you may see people using [R](https://www.r-project.org/) or [Python](https://www.python.org/).  For visualization on the web, you often see JavaScript libraries just as [d3.js](https://d3js.org/).

What we'll focus on today is an example using the R programming language and two of its libraries which are commonly used for data analysis and visualization: dplyr and ggplot2.  R is a programming language that is commonly used for data analysis.  As R is open source, people are also free to contribute libraries to it that help to extend its functionality in ways that allow you to do new things, or make it easier to do existing things.  Currently there are nearly [9000 packages](https://cran.r-project.org/web/packages/) meaning that you can often reuse code instead of having to create something yourself.

#### Reference Sheets
For both of the dplyr and ggplot2 libraries, there are reference sheets available which give a quick overview of what they're capable of.  Today we'll be showing only a small subset of their functionality.  For trying things on your own, these can be very helpful.

* [Data Visualization with ggplot2 Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)
* [Data Wrangling with dplyr and tidyr Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

---

### Learning Objectives
In this tutorial we will show how to use these open source libraries to be able to explore large complex datasets.  More specifically, after this lecture you should be familiar with several methods of filtering, grouping and summarizing data, in addition to different ways of visualizing the data.  Give a complex dataset of your own, you should be able to describe different options that would allow you to explore the data.

---

### First Steps

* **Download [this zip file](https://github.com/cbdavis/Visualizing-EIA-Power-Plant-Data/archive/master.zip)** to your computer and extract its contents.
* **Open up RStudio**.  If you do not have it installed, you can [download it here](https://www.rstudio.com/products/rstudio/download/).  On the university computers you should be able to find it in the Start Menu by looking for `Mathematics & Statistics` -> `R`
* **Open a project** by doing: `File` -> `Open Project` -> `Visualizing-EIA-Power-Plant-Data.Rproj`

The file `Visualizing-EIA-Power-Plant-Data.Rproj` will be in the same folder as the rest of the files from the zip file.  When you open a project like this, it tells RStudio the "working directory", i.e. the default folder where you want to look for files.  This makes it easy for R to find all the files that you need.

Once everything is installed, **open up RStudio and install the necessary packages for R**.  In the bottom right quadrant of RStudio, there is a `Packages` tab, with an option to `Install`.  Click on this to install the following libraries: 

* [ggplot2](http://docs.ggplot2.org/current/) - this will be used to do most of the plotting.
* [dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) - slice & dice data & perform complex operations with minimal code
* [lubridate](https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html) - makes it easy to work with date and time formats in R.  

### Overview of RStudio

RStudio has four panels, and in the default config these are:

**Top Left** - Code - here you can open and work on different script files

**Top Right** - Environment/History

* This shows all the variables and functions that are currently loaded in the workspace (the "**Environment**")
* You can click on the variables to see their values, which can be useful to inspect how the code is operating.
* The **History** shows all of the commands that you have run.

**Bottom Left** - Console

* R commands can be run here
* You can also find documentation for commands by typing in ?commandName to get help, i.e. `?sum`

**Bottom Right** - Files/Plots/Packages/Help

* **Files** - This shows everything in your current working directory
* **Plots** - Once you start plotting, multiple plots will be stored here.  There are arrows in this view that allow you to navigate  between multiple plots
* **Packages** - Shows all the packages installed and currently loaded
* **Help** - Shows documentation for various functions.  

You can run lines of code by highlighting them, and then clicking on "Run" above.
You can run all the code at once by doing Code -> Run Region -> Run All

### Examples
```{r, warning=FALSE, message=FALSE, echo=FALSE}
options(stringsAsFactors = FALSE)
library(ggplot2)
library(dplyr)
library(lubridate)
library(knitr)
```

Everything shown in the gray boxes below is code that you can run by copy/pasting into the `Console` tab in RStudio.  You can also collect these statements in a new R file (`File` -> `New File` -> `R Script`)

We first need to load the libraries that we'll be using for the rest of this tutorial.  Make sure to also include `options(stringsAsFactors = FALSE)`.

```{r eval=FALSE}
options(stringsAsFactors = FALSE)
library(ggplot2)
library(dplyr)
library(lubridate)
```

To start off, we'll look at a data set that is included with R.  This is a [famous data set collected in 1936 by the statistician Ronald Fisher](https://en.wikipedia.org/wiki/Iris_flower_data_set) that documents measurements of different species of iris flowers.  It's an interesting data set since the different species have similar measurements, and in some cases it can be difficult to tell them apart simply from their measurements.

Tabular data like you would find in spreadsheets is represented within R in what are known as **data frames**.  Looking at the first few lines of the `iris` data frame, we see the following.  There are five columns: `Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width` and `Species`
```{r, eval=FALSE}
head(iris)
```

```{r echo=FALSE}
kable(head(iris))
```

The `head` command just shows us the top few rows, and you can also use the `tail` command to look at the bottom rows.

One of the nice things about data frames is that you can use the names of the columns (combined with the `$` sign) to directly access the values in that column.  Below we look at the values for the `Sepal.Length` column in the `iris` data frame.

```{r}
iris$Sepal.Length
```

---

### ggplot2
Many visualizations created with R are often created using the **[ggplot2 library](http://ggplot2.org/)**.  What's interesting about this library is that way in which it allows you to construct visualizations.  The gg in ggplot2 stands for the Grammar of Graphics. The idea is that when you create plots, you are basically writing sentences that are of the form:

`Here's my data frame` + `Here are the x and y columns` + `Apply this kind of plot to that data` + `These are the axis labels` + `here are some more additional transformations`

The syntax may look strange at first, although itâ€™s a very modular approach, and you can create very complex visualizations just by adding new parts to these sentences.

---

To visualize this, we can first do a simple scatter plot.  You'll notice with the syntax that we first start with the `iris` data frame, then we specify which columns are to be associated with the `x` and `y` values, and then we specify that we want to plot the data as points by adding `+ geom_point()`.

```{r}
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point()
```

In the following examples, you may see the code examples split over multiple lines.  The two statements below are actually equivalent, but by spreading the commands over multiple lines it can sometimes help to make things more readable by separating the code into its different functional pieces.
```{r eval=FALSE}
# same code in 1 line
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point()

# same code in 4 lines
ggplot(iris, 
       aes(x=Sepal.Length, 
           y=Sepal.Width)) + 
  geom_point()
```

---

In addition to specifying which columns represent `x` and `y` values, we can also specify which one will be used for the `colour` of the points:

```{r irisPointColor, cache=TRUE}
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + 
  geom_point()
```

---

And we can also add an additional statement, `facet_wrap`, to indicate that we want separate plots for each of the data per species.

```{r irisFacetWrap, cache=TRUE, fig.width=8, fig.height=4}
ggplot(iris, aes(x=Sepal.Length, 
                 y=Sepal.Width, 
                 colour=Species)) + 
  geom_point() + 
  facet_wrap(~Species)
```

---

Instead of just having numeric values on the axes, we can also use categorical values such as the species, and then use this to create a box plot:

```{r irisBoxplot, cache=TRUE}
ggplot(iris, aes(x=Species, y=Sepal.Length)) + geom_boxplot()
```

---

or change this to a violin plot, which is a similar concept, but shows the number of points at a particular value by the width of the shapes.
```{r irisViolin, cache=TRUE}
ggplot(iris, aes(x=Species, y=Sepal.Length)) + geom_violin()
```

---

For analyzing the data, we can use the **[dplyr library](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html)**.  The dplyr library takes a very similar approach to what we see with ggplot.  We start off with data represented in a table, or in what R calls a data frame, and then we perform a series of operations or data transformations which are connected together via the `%>%` symbol which acts as a sort of "pipe" through which data flows.  

In very general terms, we may create a series of statements that look like:

data `%>%` operation 1 `%>%` operation 2

---

As an example of what this can look like, using the iris data set again, we do the following: 

1. group the data by species using `group_by(Species)`
1. per species we calculate the mean, standard deviation, minimum, and maximum sepal lengths using the `summarize` command.

This creates new columns such as `mean_sepal_length` which is calculated via the function `mean(Sepal.Length)`

```{r eval=FALSE}
iris %>% 
  group_by(Species) %>% 
  summarize(mean_sepal_length = mean(Sepal.Length), 
            sd_sepal_length = sd(Sepal.Length), 
            min_sepal_length = min(Sepal.Length),
            max_sepal_length = max(Sepal.Length))
```

```{r echo=FALSE}
kable(iris %>% 
  group_by(Species) %>% 
  summarize(mean_sepal_length = mean(Sepal.Length), 
            sd_sepal_length = sd(Sepal.Length), 
            min_sepal_length = min(Sepal.Length),
            max_sepal_length = max(Sepal.Length)))
```


---

### Advanced Example

For a more complicated example, we use a data set on electricity generation in the US.  This data contains around 1.5 million observations on monthly generation from individual generators for the years 2001 through 2014.  To load the data, do:

```{r loadPowerPlantData, cache=TRUE}
load("./data/generationAndFuelData.RData")
```

Here we see a preview of the data where we only look at the columns for `plant_name`, `state`, `general_fuel_name` (the fuel type), `date`, and `netgen` (the amount of electricity generated).  For this dataset, the `date` column actually represents the month and year, and all days are listed as the 15th of the month.

```{r, eval=FALSE}
head(generationAndFuelData[,c("plant_name", "state", "general_fuel_name", "date", "netgen")])
```

```{r showDataSample, cache=TRUE, echo=FALSE}
kable(head(generationAndFuelData[,c("plant_name", "state", "general_fuel_name", "date", "netgen")]))
```

---

This is too much data to visualize, so we'll have to summarize it first.  As an example, we 

1. filter by all the generators in the `state` of Texas
1. group all values by `date` and `general_fuel_name`
1. sum up the total amount of electricity generation by date (per month in this case) and by the `general_fuel_name`.

```{r texasGenerationFilter, cache=TRUE}
tmp = generationAndFuelData %>% 
  filter(state == "TX") %>% 
  group_by(date, general_fuel_name) %>% 
  summarize(total_generation = sum(netgen, na.rm=TRUE))
```

Next we plot the values where the x axis is the `date`, the y axis shows the `total_generation` per date and fuel as calculated previously, and we color the data by the `general_fuel_name`.  We then use `+ geom_line()` to specify that lines should be drawn for the data.  Because we specified `colour=general_fuel_name` this means that the lines will be grouped by the `general_fuel_name`.
```{r texasGenerationLines, cache=TRUE}
ggplot(tmp, aes(x=date, 
                y=total_generation, 
                colour=general_fuel_name)) + 
  geom_line()

```

---

We can also stack the values per date so we can get an overview of how much generation from each fuel type contributes to the whole.
```{r}
ggplot(tmp, aes(x=date, 
                y=total_generation, 
                fill=general_fuel_name)) + 
  geom_area()
```

---

What we see with this is that there's a lot of variation over the course of a year, likely due to aspects such as increased air conditioning demand in the summer.  To smooth this out, we can also sum up the total amount of generation per fuel type per year.

In the steps below we:

1. Keep all data for generators in Texas (`state == "TX"`)
1. Use `mutate` to add a new column called `year` that is derived from the year value of the date
1. Group all data into blocks by the year and fuel type
1. Per block, sum up the total amount of generation.

```{r texasYearlyGenStackedGraph, cache=TRUE}
tmp = generationAndFuelData %>% 
  filter(state == "TX") %>% 
  mutate(year = year(date)) %>%
  group_by(year, general_fuel_name) %>% 
  summarize(total_generation = sum(netgen))

ggplot(tmp, aes(x=year, 
                y=total_generation, 
                fill=general_fuel_name)) + 
  geom_area()
```

---

We can also do this for the entire US by using the `facet_wrap` command to create a plot for every single `state`.  Note how we specify `scales="free_y"` for the facet wrap so that the y axes for the plots are scaled to the maximum values in each states.  Without this, we would only be able to clearly see the data for the states that are the largest producers of electricity.

From this plot, we can see the diversity across the US states in terms of the types of fuel used.  It also becomes clear which states have changed their fuel types over time.  In particular, you can see large amounts of wind capacity being installed in the states in the Midwest of the country, and a general shift away from coal to increased use of natural gas.

In the previous stacked area plots, it can be a little difficult to distinguish between the colors in the plots.  To help with this, we use:

`geom_line(aes(ymax=total_generation), position="stack", size=0.1)`

This adds a small black line which corresponds to the stacked values calculated from the `total_generation` values.

```{r allStatesFacetWrap, fig.width=16, fig.height=10, cache=TRUE}
tmp = generationAndFuelData %>% 
  mutate(year = year(date)) %>%
  group_by(year, general_fuel_name, state) %>% 
  summarize(total_generation = sum(netgen))

ggplot(tmp, aes(x=year, 
                y=total_generation, 
                fill=general_fuel_name)) + 
  geom_area() + 
  geom_line(aes(ymax=total_generation), position="stack", size=0.1) + 
  facet_wrap(~state, scales="free_y")
```

---

Similarly, we can analyze yearly generation from different sources for the entire US.  Again we use a `facet_wrap` with independent scaling of the y axes.  Additionally, `expand_limits` is specified to make sure that the minimum value shown on the y axes is zero.

What we can see with these graphs is that generation from coal is going down, while that from natural gas is increasing.  It's also interesting to note that generation from solar and wind are increasing at a very fast pace, although they are still only a small part of total 

```{r entireUSGenerationByFuelType, cache=TRUE, fig.width=10, fig.height=4}
tmp = generationAndFuelData %>% 
  mutate(year = year(date)) %>%
  group_by(year, general_fuel_name) %>% 
  summarize(total_generation = sum(netgen))

ggplot(tmp, aes(x=year, y=total_generation)) + 
  geom_line() + 
  facet_wrap(~general_fuel_name, scales="free_y", ncol=5) + 
  expand_limits(y=0)
```

---

We can also find out which states were the top generators of electricity from wind in 2014

1. `mutate` lets us add new columns based on values in other columns.  The `date` column contains values such as `12-15-2014`.  By using `year = year(date)` we create a new column `year` that is based on the year value of the date, or in the example of `12-15-2014`, `2014`
1. We `filter` for all generation data where the `general_fuel_name` is `Wind` and for where the `year` is `2014`.
1. We use `group_by` to group all the data into blocks per `state`.
1. Per block, we `summarize` to create a new column `total_generation` which is the sum of the values in the `netgen` column
1. Finally we sort the results based on the descending values of `total_generation`

```{r topWindStates2014}
tmp = generationAndFuelData %>% 
  mutate(year = year(date)) %>%
  filter(general_fuel_name == "Wind", year == 2014) %>%
  group_by(state) %>%
  summarize(total_generation = sum(netgen)) %>% 
  arrange(desc(total_generation))

```

```{r eval=FALSE}
head(as.data.frame(tmp))
```

```{r echo=FALSE}
kable(head(as.data.frame(tmp)))
```

---

### Existing, Planned, Cancelled and Retired Generators

We now load data that has been processed from the [EIA Form 860](https://www.eia.gov/electricity/data/eia860/)

```{r}
load("./data/operableProposedCancelledAndRetiredGenerators.RData")
```

This data comes from 2014 which is the last year in which they have the full data.  Specifically, the data comes from the 3_1_Generator_Y2014.xlsx spreadsheet.  In your RStudio environment, you'll see three new data frames:

* `operableGenerators`
* `proposedGenerators`
* `retiredAndCancelledGenerators`

If you click on each of these in the `Environment` tab in RStudio, you'll be able to get an idea of their contents, and what properties of these generators you can analyze.

---

Now we'll try to see what we can find in the data.  For example, what are the 10 most important fuel sources for currently operating generators?

For this we do the following:

1. Group the data into blocks based on `fuelName`
1. Per block, sum up the `nameplate_capacity_mw` into a new column named `total_capacity_mw`
1. Sort the results based on descending values for `total_capacity_mw`
1. Return only the rows with the top 10 values

```{r findTop10Fuels, message=FALSE}
top_10_fuels = operableGenerators %>% 
  group_by(fuelName) %>% 
  summarise(total_capacity_mw = sum(nameplate_capacity_mw)) %>% 
  arrange(desc(total_capacity_mw)) %>% top_n(10)
```

```{r, eval=FALSE}
# show us what is contained in this data frame
print(top_10_fuels)
```

```{r, echo=FALSE}
kable(top_10_fuels)
```

We can also see how this compares to the top ten fuels used for proposed generators:

```{r, eval=FALSE}
proposedGenerators %>% 
  group_by(fuelName) %>% 
  summarise(total_capacity_mw = sum(nameplate_capacity_mw)) %>% 
  arrange(desc(total_capacity_mw)) %>% top_n(10)
```

```{r, echo=FALSE, message=FALSE}
kable(proposedGenerators %>% 
  group_by(fuelName) %>% 
  summarise(total_capacity_mw = sum(nameplate_capacity_mw)) %>% 
  arrange(desc(total_capacity_mw)) %>% top_n(10))
```

...and for retired or cancelled generators:

```{r, eval=FALSE}
retiredAndCancelledGenerators %>% 
  group_by(fuelName) %>% 
  summarise(total_capacity_mw = sum(nameplate_capacity_mw)) %>% 
  arrange(desc(total_capacity_mw)) %>% top_n(10)
```

```{r, echo=FALSE, message=FALSE}
kable(retiredAndCancelledGenerators %>% 
  group_by(fuelName) %>% 
  summarise(total_capacity_mw = sum(nameplate_capacity_mw)) %>% 
  arrange(desc(total_capacity_mw)) %>% top_n(10))
```

Just from looking at this, we see that the US is to some extent transitioning away from fossil fuels and starting to increasing its amount of generation from renewables.  To get a better understanding of these trends, we can put all this information into a single graph.  We'll have to do this in a series of steps.

We create a new data frame `retired_per_year_per_fuel` to indicate how much generation per capacity per year and per fuel has been retired (or is planned to be retired).

The steps are:

1. Group rows from `retiredAndCancelledGenerators` into blocks based on distinct values of `retirement_year` and `fuelName`
1. Filter using `!is.na` to make sure that we only get rows where `fuelName`, `nameplate_capacity_mw` and `retirement_year` are not [missing data](http://www.statmethods.net/input/missingdata.html).
1. Use the statement `fuelName %in% top_10_fuels$fuelName` to only keep data for the top 10 fuels as defined in the `fuelName` column of the `top_10_fuels` data frame which we created above.
1. Only keep entries where the `retirement_year` is after the year 2000
1. Per block of data (from the `group_by` statement), sum up the `nameplate_capacity_mw` and store the values in a new column named `total_capacity_retired_mw`.


```{r}
retired_per_year_per_fuel = retiredAndCancelledGenerators %>% 
  group_by(retirement_year, fuelName) %>% 
  filter(!is.na(fuelName), 
         !is.na(nameplate_capacity_mw), 
         !is.na(retirement_year), 
         fuelName %in% top_10_fuels$fuelName, 
         retirement_year > 2000) %>%
  summarise(total_capacity_retired_mw = sum(nameplate_capacity_mw))
```

We do the same steps for the operating generators, but using the column `operating_year` instead of `retirement_year`;

```{r}
operable_per_year_per_fuel = operableGenerators %>% 
  group_by(operating_year, fuelName) %>% 
  filter(!is.na(fuelName), 
         !is.na(nameplate_capacity_mw), 
         !is.na(operating_year), 
         fuelName %in% top_10_fuels$fuelName, 
         operating_year > 2000) %>%
  summarise(total_capacity_installed_mw = sum(nameplate_capacity_mw))
```

...and now for the proposed generators we do the same, but using the column `current_year` instead of `current_year`;

```{r}
proposed_per_year_per_fuel = proposedGenerators %>% 
  group_by(current_year, fuelName) %>% 
  filter(!is.na(fuelName), 
         !is.na(nameplate_capacity_mw), 
         !is.na(current_year), 
         fuelName %in% top_10_fuels$fuelName, 
         current_year > 2000) %>%
  summarise(total_capacity_installed_mw = sum(nameplate_capacity_mw))
```

We now want to plot data from multiple data frames, although in the previous plotting examples we only plotted values from a single data frame.  In order to plot a bar chart using data from the `operable_per_year_per_fuel`, you could do the following:

1. Set the x and y values based on the `operating_year` and `total_capacity_installed_mw` respectively
1. Set the fill color based on the `fuelName` values
1. Use `geom_bar` to indicate that we want a bar chart and specify `stat="identity"` to indicate that we will stack up the bars and their heights will be based on the y values.


```{r}
ggplot(data=operable_per_year_per_fuel, 
           aes(x=operating_year, y=total_capacity_installed_mw, fill=fuelName)) + 
           geom_bar(stat="identity")
```

We can also rearrange this in the form of `ggplot()` + `geom_bar(...)` as shown below.  

The implication of this is that we can also write statements of the form:

`ggplot()` + `geom_bar(...)` + `geom_bar(...)` + `geom_bar(...)`

```{r, eval=FALSE}
# version 1 - can use when working with single data frames
ggplot(data=operable_per_year_per_fuel, 
           aes(x=operating_year, y=total_capacity_installed_mw, fill=fuelName)) + 
           geom_bar(stat="identity")

# version 2 - can use when working with multiple data frames
ggplot() + 
  geom_bar(data=operable_per_year_per_fuel, 
           aes(x=operating_year, y=total_capacity_installed_mw, fill=fuelName), 
           stat="identity")
```

Putting this all together, we get the code below with a few small adjustments:

* For data on proposed generators, we use `fill="black"` to more easily distinguish plants that don't exist yet
* In the `facet_wrap`, we use `scales="free_y"` so that the y axes are scaled independently from each other to better show the differences between fuel types.
* To add a horizontal line at 0, we use `geom_hline(yintercept=0)`


```{r plotOperatingRetiredAndProposedCapacity, fig.width=12, fig.height=8, warning=FALSE}
ggplot() + 
  geom_bar(data=operable_per_year_per_fuel, 
           aes(x=operating_year, y=total_capacity_installed_mw, fill=fuelName), 
           stat="identity") +
  geom_bar(data=proposed_per_year_per_fuel, 
           aes(x=current_year, y=total_capacity_installed_mw), 
           stat="identity", fill="black") + 
  geom_bar(data=retired_per_year_per_fuel, 
           aes(x=retirement_year, y=-total_capacity_retired_mw, fill=fuelName), 
           stat="identity") + 
  facet_wrap(~fuelName, scales="free_y") + 
  geom_hline(yintercept=0)
```


### Conclusion

This has been just a brief introduction into data analysis and visualization, and there is clearly much more that is possible.  When choosing the types of tools that you will use for this, it is also important to think not just in terms of programming languages, but also about the communities around them.  

With languages such as R, Python and JavaScript, there are large numbers of people who are actively using these, which means that it is easy to find documentation and help.  Furthermore, the open source nature of these means that people are continually developing new libraries which help to provide additional functionality that may be useful for you.  In practice, you may find yourself using several libraries developed by different people, which help you to manage aspects of data gathering, analysis and visualization.